#!/usr/bin/python

import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))

from src import lexer as lexerModule

cmdLine = sys.argv

if len(cmdLine) != 2:
    print("Usage: bin/lexer <source-file>")
    quit()
else:
    fileName = cmdLine[1]
    sourceFile = open(fileName, "r")
    data = sourceFile.read()

# Test it out

# Give the lexer some input
lexerModule.lexer.input(data)
tokenCountDict = {}
tokenDict = {}

# Tokenize
while True:
    tok = lexerModule.lexer.token()
    if not tok: 
        break      # No more input
    tokenCountDict.update({tok.type: tokenCountDict.get(tok.type,0)+1 })
    tokenDict.update({tok.type: tokenDict.get(tok.type,set())|{tok.value}})

# Print stats
print '{:^40} {:^12} {:^30}'.format("Token", "Occurrences", "Lexemes")
print '-' * 84
for i in tokenDict:
    lexemeList = list(tokenDict[i])
    print '{:^40} {:^12} {:^30}'.format(i, tokenCountDict[i], lexemeList[0])
    for j in xrange(1, len(lexemeList)): 
        print '{:^40} {:^12} {:^30}'.format("", "", lexemeList[j])
#print tokenDict
#print tokenCountDict
